---
title: "DisCon Pilot Summary"
output: html_document
---

```{r setup, include=FALSE}
#Libraries
knitr::opts_chunk$set(echo = FALSE, warning = FALSE) #no code, no warning printed
library(knitr)
library(tidyverse)
library(ggplot2)
library(jsonlite)
library(tidyr)
library(stringr)
library(dplyr)
library(ggthemes)
library(langcog)
```

```{r data loading, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE) 

#Pilot data preprocessing
files <- dir("../../pilot_1_raw_data/production-results")

raw_data <- data_frame()
for (f in files) {
  jf <- paste("../../pilot_1_raw_data/production-results/",f,sep="")
  jd <- fromJSON(paste(readLines(jf), collapse=""))
  id <- as_data_frame(jd$answers$data$data) %>%
    mutate(workerid = jd$WorkerId)
  raw_data <- bind_rows(raw_data, id)
}

data_pilot_another <- raw_data %>%
  mutate(distribution = as.character(distribution),
         distribution = factor(distribution, levels = c("c(6, 0, 0)", "c(4, 2, 0)", "c(2, 2, 2)")))

#Recency "Here's another one" data preprocessing
files <- dir("../../recency_raw_data/production-results")

raw_data <- data_frame()
for (f in files) {
  jf <- paste("../../recency_raw_data/production-results/",f,sep="")
  jd <- fromJSON(paste(readLines(jf), collapse=""))
  id <- as_data_frame(jd$answers$data$data) %>%
    mutate(workerid = jd$WorkerId)
  raw_data <- bind_rows(raw_data, id)
}

data_recency_another <- raw_data %>%
  mutate(distribution = as.character(distribution),
         distribution = factor(distribution, levels = c("c(5, 1, 0)", "c(2, 2, 2)")))

data_ip <- data_recency_another %>%
  filter(phase == 'training') %>%
  group_by(workerIp) %>%
  summarise(correct = mean(correct_item))

data_recency_another <- data_recency_another %>% 
  distinct(workerIp, trial, slide, .keep_all = TRUE)

#Recency "Here's the last one." data preprocessing
files <- dir("../../recency_last_raw_data/production-results")

raw_data <- data_frame()
for (f in files) {
  jf <- paste("../../recency_last_raw_data/production-results/",f,sep="")
  jd <- fromJSON(paste(readLines(jf), collapse=""))
  id <- as_data_frame(jd$answers$data$data) %>%
    mutate(workerid = jd$WorkerId)
  raw_data <- bind_rows(raw_data, id)
}

data_recency_last <- raw_data %>%
  mutate(distribution = as.character(distribution),
         distribution = factor(distribution, levels = c("c(5, 1, 0)", "c(2, 2, 2)")))

data_ip <- data_recency_last %>%
  filter(phase == 'training') %>%
  group_by(workerIp) %>%
  summarise(correct = mean(correct_item))

data_recency_last <- data_recency_last %>% 
  distinct(workerIp, trial, slide, .keep_all = TRUE)

#Recency look data preprocessing
files <- dir("../../recency_look_raw_data/production-results")

raw_data <- data_frame()
for (f in files) {
  jf <- paste("../../recency_look_raw_data/production-results/",f,sep="")
  jd <- fromJSON(paste(readLines(jf), collapse=""))
  id <- as_data_frame(jd$answers$data$data) %>%
    mutate(workerid = jd$WorkerId)
  raw_data <- bind_rows(raw_data, id)
}

data_recency_look <- raw_data %>%
  mutate(distribution = as.character(distribution),
         distribution = factor(distribution, levels = c("c(5, 1, 0)", "c(2, 2, 2)")))

data_ip <- data_recency_look %>%
  filter(phase == 'training') %>%
  group_by(workerIp) %>%
  summarise(correct = mean(correct_item))

data_recency_look <- data_recency_look %>% 
  distinct(workerIp, trial, slide, .keep_all = TRUE)

#Combine recency data
data_recency <- bind_rows(data_recency_another, data_recency_last, data_recency_look)
```

```{r sanity checks, include=FALSE} 
#remove duplicated ips and workers who do not pass the training threshold
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)

# Training threshold check for data_pilot_another
data_pilot_another %>%
  filter(phase == 'training') %>%
  group_by(workerid) %>%
  summarise(correct = mean(correct_item))

drop <- data_pilot_another %>%
  filter(phase == 'training') %>%
  group_by(workerid) %>%
  summarise(correct = mean(correct_item)) %>%
  filter(correct < 0.83) %>%
  pull(workerid)

data_pilot_another <- data_pilot_another %>%
  filter(!workerid %in% drop)

# IP check for data_recency
data_recency <- data_recency %>% 
  distinct(workerIp, trial, slide, .keep_all = TRUE)

# Training threshold check for data_recency
data_recency %>%
  filter(phase == 'training') %>%
  group_by(workerid) %>%
  summarise(correct = mean(correct_item))

drop <- data_recency %>%
  filter(phase == 'training') %>%
  group_by(workerid) %>%
  summarise(correct = mean(correct_item)) %>%
  filter(correct < 0.83) %>%
  pull(workerid)

data_recency <- data_recency %>%
  filter(!workerid %in% drop)
```

# Pilot experiment

## Descriptives

### Task description
Each experiment contains 6 trials. Each trial contains 6 training slides (non-ambiguous utterance) and 1 test slide (ambiguous utterance), as shown below. 


![Training slide](../pictures/pilot_training.png){width=250px} ![Test slide](../pictures/pilot_test.png){width=250px}

The items appearing in a trial belong to a set of 3 categories of items (for e.g. musical instruments, fruits, vehicles) that is unique across 6 trials. We run the experiment with distributions (6-0-0), (4-2-0), and (2-2-2), with each number corresponding to how many times a category has items appear in the trial. 

### Sample size
We remove responses that get less than 5/6 correct in training slides. If there are duplicated IPs, we only take the first response.
```{r sample size data_pilot_another, echo=FALSE}
# summarise all unique ips across 3 experiments (do this after general description of task)

sample_size <- data_pilot_another %>%
  distinct(workerid, .keep_all = TRUE)

sample_size %>%
 summarise(n = n()) %>%
 kable()
```

### Finding
```{r plot1, fig.width = 8, echo=FALSE}
plot1 <- data_pilot_another %>%
  filter(phase == 'test') %>%
  group_by(distribution, workerid) %>%
  summarise(correct = mean(correct_target1),
            correct2 = mean(correct_target2),
            correct3 = mean(correct_target3)) %>%
  gather(item, prop_correct, -distribution, -workerid) %>%
  group_by(distribution, item) %>%
  multi_boot_standard(col = "prop_correct")


ggplot(plot1,
       aes(x = item, y=mean, fill=item)) +
  geom_bar(stat='identity') +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  scale_fill_solarized(name = "Chosen item",
                       breaks = c("correct", "correct2", "correct3"),
                       labels = c("most frequent", "second most frequent", "least frequent"))+
  facet_grid(~distribution, 
             labeller = as_labeller(c(`c(6, 0, 0)` = "Distribution\n(6-0-0)", `c(4, 2, 0)` = "Distribution\n(4-2-0)", `c(2, 2, 2)` = "Distribution\n(2-2-2)"))) +
  geom_hline(yintercept = 1/3, lty=2) +
  ylim(0, 1) +
  theme_few() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(x="", y= "proportion chosen")
```

There is a graded response in distribution (4-2-0) corresponding to the frequency of appearance of each category. This fits with our hypothesis that people use common ground to resolve anaphora. 

However, this result could also be driven by a recency effect where people simply choose according to the category of the last seen item.

```{r plot2, echo=FALSE}
plot2 <- data_pilot_another %>%
  filter(phase == "test", distribution != "c(6, 0, 0)") %>%
  group_by (distribution, workerid) %>%
  summarise (lastInput = mean(same_lastInput),
             n = n()) %>% 
  multi_boot_standard(col = "lastInput")

ggplot(plot2,
       aes(x = distribution, y = mean, fill = distribution)) +
  geom_bar(stat='identity', width = 0.3) +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  scale_fill_solarized(name = "Distribution",
                       breaks = c("c(6, 0, 0)", "c(4, 2, 0)", "c(2, 2, 2)"),
                       labels = c("(6-0-0)", "(4-2-0)", "(2-2-2)"))+
  geom_hline(yintercept = 1/3, lty=2) +
  ylim(0, 1) +
  theme_few() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(x="", y= "proportion chosen same as last item")
```

In order to look at the recency, we manipulate the experiment 
2 new types of expression for the test slide


