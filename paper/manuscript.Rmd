---
title             : "What’s she talking about? Category based discourse inferences in early childhood"
shorttitle        : "Discourse inferences in early childhood"

author: 
  - name          : "Manuel Bohn"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "Jahnallee 59, 04109 Leipzig, Germany"
    email         : "manuel.bohn@uni-leipzig.de"
  - name          : "Khuyen Nha Le"
    affiliation   : "1"
  - name          : "Benjamin Peloquin"
    affiliation   : "1"
  - name          : "Bahar Köymen"
    affiliation   : "3"
  - name          : "Michael C. Frank"
    affiliation   : "1"            

affiliation:
  - id            : "1"
    institution   : "Stanford University"
  - id            : "2"
    institution   : "Leipzig University"
  - id            : "3"
    institution   : "University of Manchester"

authornote: |
  We thank Megan Merrick and Sabina Zacco for their help with the data collection. MB received funding from the European Union’s Horizon   2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement no. 749229.

abstract: |
  tbd... 
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["library.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library(papaja)
library(tidyverse)
library(ggplot2)
library(brms)
library(ggthemes)
library(langcog)
library(ggpubr)
library(BayesFactor)
library(broom)
library(coda)
library(reshape2)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
knitr::opts_chunk$set(echo = F, warning = F, message = F)
```

```{r load data}
ex1_data <- read_csv(file="../data/data_ex1.csv")
ex2_data <- read_csv(file="../data/data_ex2.csv")
ex3_data <- read_csv(file="../data/data_ex3.csv")
```

# Experiment 1

All experimental procedures, sample sizes and statistical analysis were pre-registered (see https://osf.io/9ypxn and https://osf.io/fyaxq). The experimental procedure can be found in the assoicated online repository at https://github.com/manuelbohn/disCon.

## Participants
```{r participants-ex1, include = F}
desc_ex1 <- ex1_data%>%
  group_by(age_group)%>%
  summarise(n = length(unique(id)), 
            age = mean(age_num), 
            min_age = min(age_num),
            max_age = max(age_num))
```

We obtained valid data from 71 children, including `r desc_ex1%>%filter(age_group == "2")%>%pull(n)` 2-year-olds (mean = `r desc_ex1%>%filter(age_group == "2")%>%pull(age)`, range = `r desc_ex1%>%filter(age_group == "2")%>%pull(min_age)` - `r desc_ex1%>%filter(age_group == "2")%>%pull(max_age)`), `r desc_ex1%>%filter(age_group == "3")%>%pull(n)` 3-year-olds (mean = `r desc_ex1%>%filter(age_group == "3")%>%pull(age)`, range = `r desc_ex1%>%filter(age_group == "3")%>%pull(min_age)` - `r desc_ex1%>%filter(age_group == "3")%>%pull(max_age)`) and `r desc_ex1%>%filter(age_group == "4")%>%pull(n)` 4-year-olds (mean = `r desc_ex1%>%filter(age_group == "4")%>%pull(age)`, range = `r desc_ex1%>%filter(age_group == "4")%>%pull(min_age)` - `r desc_ex1%>%filter(age_group == "4")%>%pull(max_age)`). We tested a larger sample of 2-year-olds because we expected a weaker effect in this age group. In addition, 12 children were recruited but not tested becasue their parents reported less than 75% of English exposure at home. Ten children started the experiment but did not finish it because they became impatient (7) or the equipment broke (3). Three children were tested but excluded becasue they were correct in less than 5/6 training trials (see below). All children were recruited from the floor of a Children's museum in San José, California, USA. The population from which this sample is drawn is characterised by diverse ethnic background and high socioeconimic status. Parents gave informed consent and provided demographic information. All experiments reported in this paper were approved by the Stanford Institutional Review Board (protocol no. 357 19960).

```{r fig1, include = T, fig.align = "center", fig.cap = "Left: Screenshot from the experimental setup. Right: Stimuli pictures for the four categories: fruits, vehicles, clothes and mammals.", out.width="450px"}
knitr::include_graphics("../figures/setup.png")
```

## Method

Study materials were presented as a picture book on a tablet computer [@frank2016using]. Children reponded by touching objects on the screen. Responses were automatically saved. The experimenter guided children through the procedure and read out general instructions. The study was framed as visit to the house of the little animals which would show the child the things they have at home. Utterances made by the different animals were pre-recorded from native English speakers, with one speaker per animal. On each trial, children saw one animal in the middle of the screen with three objects above them (Figure \ref{fig:fig1}, left). Each objects was from different category (mammals, vehicles, clothes and fruits). For each category, we had pictures of seven different category memebers (e.g. for vehicles: car, truck, train, bus, airplane, boat and motorbike, see Figure \ref{fig:fig1}, right). The trial started with six training rounds, in which the animal named one of the objects above them, asking the child to touch it (e.g. "Look at that, can you touch the horse"). From one round to the next, the pictures changed but the categories remained the same. For example, children saw a skirt, a horse and a motorcylce on the first training round and a jacket, a dog and a bus on the second. During training, the speaker consitently named objects from the same target category. After six training rounds, children received a test round in which the speaker used a pronoun to refer to one of the objects ("Look at that, can you touch *it*"). Categories were ranomdly selected at the beginning of each trial and so was the order of pictures within each category. The position of each picture (left, right mddle) was also randomly determined on each round. Children received four trials, one with each category as the target.       

## Results 
```{r experiment1, cache = T, include = F}

bf_t_overall <- ex1_data %>%
  group_by(id) %>%
  summarise(correct = mean(correct)) %>%
  summarise(correct = list(correct)) %>%
  mutate(mean= mean(unlist(correct)),
         bf = extractBF(ttestBF(unlist(correct), mu = 1/3))$bf)

bf_t_age <- ex1_data %>%
  group_by(age_group, id) %>%
  summarise(correct = mean(correct)) %>%
  summarise(correct = list(correct)) %>%
  group_by(age_group)%>%
  mutate(mean= mean(unlist(correct)),
         bf = extractBF(ttestBF(unlist(correct), mu = 1/3))$bf)


ex1_model_data <- ex1_data%>%
  mutate(age_num = age_num - mean(age_num))


prior_ex1_m1 <- c(set_prior("normal(0,10)", class = "b", coef = "age_num"))

ex1_m1 <- brm(correct ~ age_num + (1|id) + (1|speaker),
                    data = ex1_model_data, family = bernoulli(),
          control = list(adapt_delta = 0.99),
          sample_prior = F,
          prior = prior_ex1_m1, 
          chains = 4,
          cores = 4,
          save_all_pars = TRUE,
          iter = 50000)%>%
  saveRDS(., "../saves/ex1_model1.rds")

ex1_m1 <-readRDS("../saves/ex1_model1.rds")


ex1_m2 <- brm(correct ~ 1 + (1|id) + (1|speaker),
                    data = ex1_model_data, family = bernoulli(),
          control = list(adapt_delta = 0.99),
          sample_prior = F,
          chains = 4,
          cores = 4,
          save_all_pars = TRUE,
          iter = 50000)%>%
  saveRDS(., "../saves/ex1_model2.rds")

ex1_m2 <-readRDS("../saves/ex1_model2.rds")

ex1_waic <- brms::waic(ex1_m1, ex1_m2, compare = F)

ex1_weights <- model_weights(ex1_m1, ex1_m2, weights = "waic")

bf_ex1 <- bayes_factor(ex1_m1, ex1_m2, log = FALSE, maxiter = 5000)

t1 <- tibble(
  Model = c("correct ~ age + RE","correct ~ 1 + RE"),
  WAIC = c(ex1_waic$loo$ex1_m1$estimates[3,1],ex1_waic$loo$ex1_m2$estimates[3,1]),
  SE = c(ex1_waic$loo$ex1_m1$estimates[3,2],ex1_waic$loo$ex1_m2$estimates[3,2]),
  weight = c(ex1_weights["ex1_m1"],ex1_weights["ex1_m2"]),
  BF = c("-",round(bf_ex1$bf,2)))
``` 

```{r plots1, include = F}
pex1_1 <- ex1_data %>%
  group_by(experiment,age_group,age_num, id) %>%
  summarise(correct = mean(correct)) 

pex1_2 <- pex1_1 %>%
  group_by(experiment,age_group) %>%
  multi_boot_standard(col = "correct")

samples1 <- posterior_samples(ex1_m1, "^b")%>%
  mutate(sample = 1:length(b_age_num))

samples <- expand_grid(samples1,ex1_model_data$age_num)%>%
  mutate(y = plogis(b_Intercept + b_age_num * `ex1_model_data$age_num`),
         age = `ex1_model_data$age_num` + mean(ex1_data$age_num),
         experiment = "simple_inference")%>%
  filter(sample < 1000)

map_model <- tibble(
  age = ex1_model_data$age_num,
  int = fixef(ex1_m1)[1,1],
  slope = fixef(ex1_m1)[2,1]
)%>%
  mutate(y = plogis(int + slope * age),
         age = age + mean(ex1_data$age_num))

p1 <- ggplot() +
  geom_hline(yintercept = 1/3, lty=2, size = 1)+
  geom_jitter(data = pex1_1,aes(x = age_num, y= correct, col = experiment), width = .00, height = .01, alpha = .5)+
  geom_line(data = samples, aes(x = age, y = y, group = sample), col = "#CC6677", size = .025)+
  geom_line(data = map_model, aes(x = age, y = y), col = "#CC6677", size = 1)+
  #geom_smooth(data = ex1_data,aes(x = age_num, y= correct, col = experiment), method = "glm", method.args = list(family = "binomial"), se = T, alpha = .5, size = 1.5)+
  labs(x="Age",y="Proportion correct")+
  theme_few() +
  ylim(-0.05,1.05)+
  xlim(2,5)+
  guides(alpha = F, col = F)+
  scale_color_manual(values = "#CC6677")



# density plot

plot_post <- ex1_data %>%
  group_by(age_group,id) %>%
  summarise(correct = mean(correct))%>%
  summarise(correct = list(correct)) %>%
  group_by(age_group) %>%
  mutate(posterior = list((ttestBF(unlist(correct), mu = 1/3, posterior = T, iterations = 1000)[,"mu"])))%>%
  select(-correct)


plot_dens_ci <- plot_post %>%
  summarise(mode = estimate_mode(unlist(posterior)),
            lci = hdi_lower(unlist(posterior)),
            uci = hdi_upper(unlist(posterior)))



plot_dens <- tibble(
  age = rep(c(2,3,4), each = 1000),
  posterior = c(unlist(plot_post%>%filter(age_group == "2") %>% pull(posterior)),unlist(plot_post%>%filter(age_group == "3") %>% pull(posterior)),unlist(plot_post%>%filter(age_group == "4") %>% pull(posterior)))
)

densities <- plot_dens %>%
  group_by(age) %>%
  do(., dens = density(.$posterior))

densities_df <-
  tibble(
    age = c(rep('2', 512),
            rep('3', 512),
              rep('4', 512)),
    x = c(densities$dens[[1]]$x, 
          densities$dens[[2]]$x,
          densities$dens[[3]]$x),
    y = c(densities$dens[[1]]$y,
          densities$dens[[2]]$y,
          densities$dens[[3]]$y)
  ) %>%
  group_by(age)%>%
  mutate (
    ci_shade = ifelse( age == "3",
                       ifelse( x <= plot_dens_ci%>%filter(age_group == "3")%>%pull(lci) | x >= plot_dens_ci%>%filter(age_group == "3")%>%pull(uci), "OFF", "ON"),
                       ifelse(age == "2", ifelse( x <= plot_dens_ci%>%filter(age_group == "2")%>%pull(lci) | x >= plot_dens_ci%>%filter(age_group == "2")%>%pull(uci), "OFF", "ON"),
      ifelse( x <= plot_dens_ci%>%filter(age_group == "4")%>%pull(lci) | x >= plot_dens_ci%>%filter(age_group == "4")%>%pull(uci), "OFF", "ON"))))


post_plot <- ggplot(plot_dens, aes(posterior, group = age)) +
  geom_vline(xintercept = 1/3, lty=2, size = 1)+
  geom_area(data = densities_df %>% filter(ci_shade == "ON"), aes(x = x, y = y, fill = age), alpha = .5) + 
  geom_density(alpha = .5, size = 1)+
  labs(y="Probability density", x="Proportion correct")+
  theme_few() +
  xlim(-0.05,1.05)+
  guides(alpha = F)+
  scale_fill_ordinal(name = "Age")
```

```{r fig2, include = T, fig.align = "center", fig.cap = "A: Posterior probability distribution for the mean for each age bin. Shaded regions indicate 95\\% CIs. B: Correct  responses for age continously. Transparent dots show aggregated data from individual participants. Red line with grey shows the smoothed conditional mean of the data in each condition..", fig.width=10, fig.height=4}

ggarrange(post_plot,p1, nrow = 1, labels = c("A","B"))
```

The dependent variable in all analysis was whether the touched object at test was from the same category as the objects named throughout the training rounds. All following analysis were computed in R [@R-base]. As a first step, we aggregated respones across trials for each child and compared the proportion of correct responses to a level expected by chance (33% correct) within each age bin. We used the function `ttestBF` from the R-package `BayesFactor` [@R-BayesFactor] to compute a Bayes factor (BF) in favor of the hypothesis that performance is above chance (see Figure \ref{fig:fig2}A). We found little evidence that 2-year olds performed above chance (mean proportion correct = `r bf_t_age%>%filter(age_group == "2")%>%pull(mean)`, BF = `r bf_t_age%>%filter(age_group == "2")%>%pull(bf)`) but found subtantial evidence for 3-year-olds (mean proportion correct = `r bf_t_age%>%filter(age_group == "3")%>%pull(mean)`, BF = `r bf_t_age%>%filter(age_group == "3")%>%pull(bf)`) and 4-year-olds (mean proportion correct = `r bf_t_age%>%filter(age_group == "4")%>%pull(mean)`, BF = `r bf_t_age%>%filter(age_group == "4")%>%pull(bf)`). 

To analyse responses continously across age we used generalized linear mixed models (GLMM) fit via the function `brm` from the R-package `brms` [@R-brms_a]. All models had default priors and included random effects for participant id and speaker. Inference was based on comparing models that differed in whether they included the key predictor of interest, in this case age. Following McElreath [-@rethinking], we compared models using WAIC (widely applicable information criterion) scores and weights. WAIC is an indicator of the model's predictive accuracy for out of sample data and model's with lower scores are preferred. WAIC weights are an estimate of the probability that this model (compared to all other models considered) will make the best predictions on new data. We quantified the evidence in favor of the model with the lowest WAIC score (highest WAIC weight) compared to alternative models by computing Bayes factors via the funtion `bayes_factor` from the R-package `brms` [@R-brms_a].

The model comparison favored the model including age as a predictor (Table \ref{tab:table1}). The model estiamte for age was positive ($\beta$ = `r fixef(ex1_m1)[2,1]`, 95% confidence interval (CI) = `r fixef(ex1_m1)[2,3]` - `r fixef(ex1_m1)[2,4]`), suggesting an increase in performance with age (see also Figure \ref{fig:fig2}B). However, the evidence in support of this model was modest, speaking against subtantial developmental gains across the age range considered. 

## Discussion

```{r table1,results = "asis"}
apa_table(
  t1
  , caption = "Model comparison for Experiment 1"
  , note = "All models had the same random effects (RE) structure. BF denotes the Bayes Factor in favor to the model with the highest WAIC weight."
  , escape = T
)
```

# Experiment 2

Registration: https://osf.io/x2k4p

## Participants

## Material and Procedure

## Results and Discussion


```{r experiment2, cache = T, include = F}

ex2_model_data <- ex2_data%>%
  mutate(age_num = age_num - mean(age_num))


prior_ex2_m1 <- c(set_prior("normal(0,10)", class = "b", coef = "age_num"),
                  set_prior("normal(0,10)", class = "b", coef = "conditionlow_input"),
                  set_prior("normal(0,10)", class = "b", coef = "age_num:conditionlow_input"))


ex2_m1 <- brm(correct ~ age_num * condition + (condition|id) + (condition|speaker),
                    data = ex2_model_data, family = bernoulli(),
          control = list(adapt_delta = 0.99),
          sample_prior = F,
          prior = prior_ex2_m1,
          chains = 4,
          cores = 4,
          save_all_pars = TRUE,
          iter = 50000)%>%
  saveRDS(., "../saves/ex2_model1.rds")

ex2_m1 <-readRDS("../saves/ex2_model1.rds")


prior_ex2_m2 <- c(set_prior("normal(0,10)", class = "b", coef = "age_num"),
                  set_prior("normal(0,10)", class = "b", coef = "conditionlow_input"))

ex2_m2 <- brm(correct ~ age_num + condition + (condition|id) + (condition|speaker),
                    data = ex2_model_data, family = bernoulli(),
          control = list(adapt_delta = 0.99),
          sample_prior = F,
          prior = prior_ex2_m2,
          chains = 4,
          cores = 4,
          save_all_pars = TRUE,
          iter = 50000)%>%
  saveRDS(., "../saves/ex2_model2.rds")

ex2_m2 <-readRDS("../saves/ex2_model2.rds")


prior_ex2_m3 <- c(set_prior("normal(0,10)", class = "b", coef = "age_num"))

ex2_m3 <- brm(correct ~ age_num + (condition|id) + (condition|speaker),
                    data = ex2_model_data, family = bernoulli(),
          control = list(adapt_delta = 0.99),
          sample_prior = F,
          prior = prior_ex2_m3,
          chains = 4,
          cores = 4,
          save_all_pars = TRUE,
          iter = 50000)%>%
  saveRDS(., "../saves/ex2_model3.rds")

ex2_m3 <-readRDS("../saves/ex2_model3.rds")


ex2_waic <- brms::waic(ex2_m1, ex2_m2,ex2_m3, compare = F)

ex2_weights <- model_weights(ex2_m1, ex2_m2,ex2_m3, weights = "waic")

bf_ex2_1 <- bayes_factor(ex2_m3, ex2_m1, log = FALSE)

bf_ex2_2 <- bayes_factor(ex2_m3, ex2_m2, log = FALSE)

t2 <- tibble(
  Model = c("correct ~ age + RE","correct ~ age * condition + RE","correct ~ age + condition + RE"),
  WAIC = c(ex2_waic$loo$ex2_m3$estimates[3,1],ex2_waic$loo$ex2_m1$estimates[3,1],ex2_waic$loo$ex2_m2$estimates[3,1]),
  SE = c(ex2_waic$loo$ex2_m3$estimates[3,2],ex2_waic$loo$ex2_m1$estimates[3,2],ex2_waic$loo$ex2_m2$estimates[3,2]),
  weight = c(ex2_weights[3],ex2_weights[1],ex2_weights[2]),
  BF = c("-",round(bf_ex2_1$bf,2),round(bf_ex2_2$bf,2)))
```

```{r table2,results = "asis"}
apa_table(
  t2
  , caption = "Model comparison for Experiment 2"
  , note = "All models had the same random effects (RE) structure. BF denotes the Bayes Factor in favor to the model with the highest WAIC weight."
  , escape = T
)
```

# Experiment 3

Registration: https://osf.io/5e9pk

## Participants

## Material and Procedure

## Results and Discussion

```{r experiment3, cache = T, include = F}

ex3_model_data <- ex3_data%>%
  mutate(age_num = age_num - mean(age_num))


prior_ex3_m1 <- c(set_prior("normal(0,5)", class = "b", coef = "intercept"),
                  set_prior("normal(0,5)", class = "b", coef = "age_num"),
                  set_prior("normal(0,5)", class = "b", coef = "conditionsame_speaker"),
                  set_prior("normal(0,5)", class = "b", coef = "age_num:conditionsame_speaker"))

ex3_m1 <- brm(correct ~ age_num * condition + (condition|id) + (condition|speaker),
                    data = ex3_model_data, family = bernoulli(),
          control = list(adapt_delta = 0.99),
          sample_prior = F,
          chains = 4,
          cores = 4,
          save_all_pars = TRUE,
          iter = 10000)%>%
   add_criterion("waic")%>%
  saveRDS(., "../saves/ex3_model1.rds")


hypothesis(ex3_m1, hypothesis = 'age_num:conditionsame_speaker = 0')

ex3_m1 <-readRDS("../saves/ex3_model1.rds")

ex3_m2 <- update(ex3_m1, 
                 formula = ~ . -age_num:conditionsame_speaker, 
                 newdata = ex3_model_data,
                 chains = 4,
                 cores = 4,
                 save_all_pars = TRUE)%>%
   add_criterion("waic")%>%
  saveRDS(., "../saves/ex3_model2.rds")

ex3_m2 <-readRDS("../saves/ex3_model2.rds")


ex3_m3 <- update(ex3_m1, 
                 formula = ~ . - age_num:conditionsame_speaker - conditionsame_speaker, 
                 newdata = ex3_model_data,
                 chains = 4,
                 cores = 4,
                 save_all_pars = TRUE)%>%
   add_criterion("waic")%>%
  saveRDS(., "../saves/ex3_model3.rds")

ex3_m3 <-readRDS("../saves/ex3_model3.rds")

bf_ex3_1 <- bayes_factor(ex3_m1, ex3_m2, log = FALSE)

bf_ex3_2 <- bayes_factor(ex3_m1, ex3_m2, log = FALSE)

t3 <- loo_compare(ex3_m1, ex3_m2, ex3_m3, criterion = "waic")%>%
  as.data.frame() %>%
  tibble::rownames_to_column("Model")%>%
  mutate(
    Model = recode(Model, ex3_m1 = "correct ~ age * condition + RE", 
                   ex3_m2 = "correct ~ age + condition + RE",
                   ex3_m3 = "correct ~ age + RE"),
    weight = exp(elpd_waic) / sum(exp(elpd_waic)),
    weight = round(weight, 3),
    WAIC = round(waic, 2),
    SE = round(se_waic,2),
    BF = c("-",round(bf_ex3_1$bf,2),round(bf_ex3_2$bf,2)))%>%
  select(Model, WAIC, SE, BF)

```



```{r table3,results = "asis"}
apa_table(
  t3
  , caption = "Model comparison for Experiment 3"
  , note = "All models had the same random effects (RE) structure. BF denotes the Bayes Factor in favor to the model with the highest WAIC weight."
  , escape = T
)
```

# General Discussion

```{r plots2}
pex2_1 <- ex2_data %>%
  group_by(condition,age_group,age_num, id) %>%
  summarise(correct = mean(correct)) 

pex2_2 <- pex2_1 %>%
  group_by(condition,age_group) %>%
  multi_boot_standard(col = "correct")


samples2 <- posterior_samples(ex2_m1, "^b")%>%
  mutate(sample = 1:length(b_age_num))

sample2 <- expand_grid(samples2,ex2_model_data$age_num)%>%
  filter(sample < 2000)%>%
  mutate(condition = ifelse(sample <1000, "high_input", "low_input"),
         y = ifelse(condition == "high_input", plogis(b_Intercept + b_age_num * `ex2_model_data$age_num`), plogis(b_Intercept + b_conditionlow_input + b_age_num * `ex2_model_data$age_num` + `b_age_num:conditionlow_input` * `ex2_model_data$age_num`)),
         age = `ex2_model_data$age_num` + mean(ex2_data$age_num))


map_model_2 <- tibble(
  age = rep(ex2_model_data$age_num, 2),
  condition = c(rep("high_input", length(ex2_model_data$age_num)),rep("low_input", length(ex2_model_data$age_num))),
  int = fixef(ex2_m1)[1,1],
  slope = fixef(ex2_m1)[2,1],
  speak = fixef(ex2_m1)[3,1],
  int_act = fixef(ex2_m1)[4,1]
)%>%
  mutate(y = ifelse(condition == "high_input", plogis(int + slope * age), plogis(int + speak + slope * age + int_act * age)),
         age = age + mean(ex2_data$age_num))

p2 <- ggplot() +
  geom_hline(yintercept = 1/3, lty=2, size = 1)+
  geom_jitter(data = pex2_1,aes(x = age_num, y= correct, col = condition), width = .00, height = .01, alpha = .5)+
  geom_line(data = sample2, aes(x = age, y = y, col = condition, group = sample), size = .025)+
  geom_line(data = map_model_2, aes(x = age, y = y, col = condition), size = 1)+
  #geom_smooth(data = ex2_data,aes(x = age_num, y= correct, col = condition), method = "glm", method.args = list(family = "binomial"), se = T, alpha = .5, size = 1.5 )+
  #geom_pointrange(data = pex2_2, aes(x = age_group+.5, y = mean, ymin = ci_lower, ymax = ci_upper, col = condition),size = .8, position = position_dodge(width = .2), pch = 4)+
  labs(x="Age",y="Proportion correct")+
  theme_few() +
  ylim(-0.05,1.05)+
  xlim(3,5)+
  guides(alpha = F)+
  scale_color_manual(name = "Input",
                   breaks = c("low_input", "high_input"),
                   labels = c("Low", "High"),
                   values = c("#CC6677", "#DDCC77"))+
  theme(legend.position = "bottom")



pex3_1 <- ex3_data %>%
  group_by(condition,age_group,age_num, id) %>%
  summarise(correct = mean(correct)) 

pex3_2 <- pex3_1 %>%
  group_by(condition,age_group) %>%
  multi_boot_standard(col = "correct")


samples3 <- posterior_samples(ex3_m1, "^b")%>%
  mutate(sample = 1:length(b_age_num))

sample3 <- expand_grid(samples3,ex3_model_data$age_num)%>%
  filter(sample < 2000)%>%
  mutate(condition = ifelse(sample <1000, "same_speaker", "different_speaker"),
         y = ifelse(condition == "different_speaker", plogis(b_Intercept + b_age_num * `ex3_model_data$age_num`), plogis(b_Intercept + b_conditionsame_speaker + b_age_num * `ex3_model_data$age_num` + `b_age_num:conditionsame_speaker` * `ex3_model_data$age_num`)),
         age = `ex3_model_data$age_num` + mean(ex3_data$age_num))


map_model_3 <- tibble(
  age = rep(ex3_model_data$age_num, 2),
  condition = c(rep("same_speaker", length(ex3_model_data$age_num)),rep("different_speaker", length(ex3_model_data$age_num))),
  int = fixef(ex3_m1)[1,1],
  slope = fixef(ex3_m1)[2,1],
  speak = fixef(ex3_m1)[3,1],
  int_act = fixef(ex3_m1)[4,1]
)%>%
  mutate(y = ifelse(condition == "different_speaker", plogis(int + slope * age), plogis(int + speak + slope * age + int_act * age)),
         age = age + mean(ex3_data$age_num))


p3 <- ggplot() +
  geom_hline(yintercept = 1/3, lty=2, size = 1)+
  geom_jitter(data = pex3_1,aes(x = age_num, y= correct, col = condition), width = .00, height = .01, alpha = .5)+
  geom_line(data = sample3, aes(x = age, y = y, col = condition, group = sample), size = .025)+
  geom_line(data = map_model_3, aes(x = age, y = y, col = condition), size = 1)+
  #geom_smooth(data = ex3_data,aes(x = age_num, y= correct, col = condition), method = "glm", method.args = list(family = "binomial"), se = T, alpha = .5, size = 1.5)+
  #geom_pointrange(data = pex3_2, aes(x = age_group+.5, y = mean, ymin = ci_lower, ymax = ci_upper, col = condition),size = .8, position = position_dodge(width = .2), pch = 4)+
  labs(x="Age",y="Proportion correct")+
  theme_few() +
  ylim(-0.05,1.05)+
  xlim(3,5)+
  guides(alpha = F)+
  scale_color_ptol(name = "Speaker",
                   breaks = c("different_speaker", "same_speaker"),
                   labels = c("Different", "Same"))+
  theme(legend.position = "bottom")


```

```{r plot2, fig.width=8, fig.height=4}
ggarrange(p2, p3, nrow = 1, labels = c("A","B"))
```



\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
